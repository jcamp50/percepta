# Analysis Report: Broadcaster 51496027
## Date: 2025-11-13

---

## Executive Summary

This analysis evaluates the performance of the Memory-Propagated Summarization system, RAG context retrieval, and video description generation for broadcaster 51496027. Key findings:

1. **✅ Summarization**: Working well with memory propagation, but summaries are too long (2300-3000 chars)
2. **❌ RAG Context Limit**: Critical issue - most recent summary alone exceeds 2000 char limit
3. **✅ Video Descriptions**: Generating quality descriptions consistently
4. **⚠️ Token Usage**: High input tokens (15k-23k) due to large context windows

---

## 1. Database Analysis

### Data Volume (21:06 - 21:56 UTC)
- **Transcripts**: 72 chunks
- **Video Frames**: 122 frames (with descriptions)
- **Chat Messages**: 4,056 messages
- **Summaries**: 9 segments (21:02 - 21:52)

### Summary Quality Progression
| Segment | Time Range | Length (chars) | Est. Tokens | Quality |
|---------|------------|----------------|-------------|---------|
| 1-3 | 21:02-21:24 | 126 | ~32 | ❌ Empty (no data) |
| 4 | 21:38-21:40 | 1,646 | ~412 | ⚠️ Partial |
| 5 | 21:40-21:42 | 2,471 | ~618 | ✅ Good |
| 6 | 21:44-21:46 | 2,962 | ~741 | ✅ Excellent |
| 7 | 21:46-21:48 | 2,671 | ~668 | ✅ Excellent |
| 8 | 21:48-21:50 | 2,331 | ~583 | ✅ Good |
| 9 | 21:50-21:52 | 2,336 | ~584 | ✅ Good |

**Observation**: Summaries are consistently 2300-3000 characters, which is **15-50% longer than the target 300-500 words** (approximately 1500-2500 characters).

---

## 2. RAG Context Limit Issue ⚠️ **CRITICAL**

### Problem
The RAG context character limit is **2000 characters** (`DEFAULT_CONTEXT_CHAR_LIMIT`), but:
- Most recent summary alone: **2300-3000 characters**
- This means **the summary alone exceeds the entire context budget**
- No room for semantically relevant chunks from retriever

### Evidence from Logs
All 3 RAG queries returned **only 1 chunk** (the most recent summary):

1. **Query**: "What do you need from a bastion in a speedrun?"
   - Context: Only most recent summary (21:50-21:52)
   - Answer: "I don't have enough information"
   - **Issue**: Summary doesn't mention bastions, but no other context was retrieved

2. **Query**: "What's going on right now?"
   - Context: Only most recent summary (21:48-21:50)
   - Answer: Used summary correctly ✅
   - **Issue**: No additional context despite semantic search

3. **Query**: "What is he trying to get from the nether?"
   - Context: Only most recent summary (21:48-21:50)
   - Answer: "I don't have enough information"
   - **Issue**: Summary mentions Nether preparation but no specific items; no other context retrieved

### Root Cause
```python
# py/reason/rag.py:37
DEFAULT_CONTEXT_CHAR_LIMIT = 2000  # Too small!
```

The most recent summary is **always prepended** and takes up 100%+ of the budget, leaving no room for:
- Semantically relevant transcripts
- Relevant video frames
- Relevant chat messages
- Other relevant summaries

---

## 3. Summarization Token Usage Analysis

### Token Breakdown (Segment 21:50-21:52)
- **Input Tokens**: 17,501
- **Output Tokens**: 443
- **Total**: 17,944 tokens

### Context Components (Estimated)
| Component | Count | Est. Tokens | Notes |
|-----------|-------|-------------|-------|
| Previous Summary | 1 | ~600 | Memory propagation |
| Video Frame Descriptions | 12 | ~4,800 | ~400 tokens each |
| Chat Messages | 377 | ~3,770 | ~10 tokens each |
| Transcripts | 9 | ~450 | ~50 tokens each |
| System Prompt | 1 | ~200 | |
| User Prompt Template | 1 | ~300 | |
| **Total Estimated** | | **~10,120** | |

**Gap**: Estimated 10k tokens but actual is 17.5k. Additional tokens likely from:
- Full video frame descriptions with enriched context (temporally-aligned transcripts/chat)
- More verbose prompt formatting
- Previous summary may be longer than estimated

### Busy Segment Analysis (21:44-21:46)
- **Input Tokens**: 23,291 (highest)
- **Output Tokens**: 532
- **Context**: 
  - 12 video frames
  - 9 transcripts
  - ~400+ chat messages (estimated from pattern)
  - Previous summary: 2,962 chars (~740 tokens)

**Observation**: Token usage scales with activity level, which is expected. However, the summaries themselves are longer than necessary.

---

## 4. Video Description Success ✅

### Performance Metrics
- **Success Rate**: ~98% (2 errors out of 100+ logs)
- **Average Description Length**: ~400 tokens
- **Refusal Rate**: 0% (after prompt improvements)
- **Quality**: Detailed, structured descriptions with all required sections

### Sample Quality (21:42:46)
- Comprehensive description of scene, participants, activity
- All overlay elements captured
- Temporal context included
- No refusals or "I can't assist" responses

**Conclusion**: Video descriptions are working excellently and maintaining visual/temporal understanding.

---

## 5. Summary Quality Assessment

### Memory Propagation ✅
- **Working**: Each summary includes the previous segment's summary
- **Example**: Segment 6 (21:44-21:46) includes full summary from Segment 5 (21:40-21:42)
- **Continuity**: Narrative flows well across segments

### Content Quality ✅
- **Comprehensive**: Covers events, visual context, chat highlights, streamer reactions
- **Temporal**: Includes specific timestamps
- **Structured**: Well-organized with clear sections

### Length Issue ⚠️
- **Target**: 300-500 words (~1500-2500 chars)
- **Actual**: 2300-3000 chars (600-750 words)
- **Impact**: 
  - Exceeds RAG context limit
  - Higher token costs
  - May be more verbose than necessary

---

## 6. Recommendations

### Immediate Fixes

#### 1. Increase RAG Context Limit
```python
# py/reason/rag.py
DEFAULT_CONTEXT_CHAR_LIMIT = 8000  # Increase from 2000 to accommodate summaries + other context
```

**Rationale**: 
- Most recent summary: ~2500 chars
- Need room for 3-5 additional relevant chunks (~500-1000 chars each)
- Total: ~6000-8000 chars

#### 2. Reduce Summary Length
**Option A**: Enforce stricter word limits in prompt
```txt
# summary_system_prompt.txt
Keep the summary between 200-350 words (not 300-500).
```

**Option B**: Post-process truncation
- Generate summary
- If > 2000 chars, truncate to 2000 chars intelligently (preserve structure)

**Option C**: Use a more concise summary format
- Remove verbose section headers
- Use bullet points instead of paragraphs
- Focus on key facts only

**Recommendation**: **Option A + B** - Update prompt to target 200-350 words, and add safety truncation.

#### 3. Optimize Summarization Context
**Reduce video frame descriptions in context**:
- Instead of full descriptions (~400 tokens each), use:
  - Short summaries (~100 tokens each)
  - Or only include "interesting" frames (not all 12)

**Reduce chat message verbosity**:
- Instead of all 377 messages, use:
  - Top 50-100 most relevant (by engagement, keywords, etc.)
  - Or aggregate similar messages

**Reduce transcript verbosity**:
- Transcripts are already short (~50 tokens each), but could aggregate similar chunks

### Future Optimizations

#### 1. Two-Tier Summary System
- **Short Summary** (200-300 words): For RAG context
- **Detailed Summary** (500-800 words): For archival/analysis
- Store both, use short one in RAG

#### 2. Adaptive Context Budget
- Allocate context budget dynamically:
  - Most recent summary: 30% (fixed)
  - Semantically relevant chunks: 70% (variable)
- If summary is too long, truncate it to fit 30% budget

#### 3. Summary Compression
- Use a second LLM pass to compress summaries for RAG
- Or use extractive summarization to create shorter versions

#### 4. Chunk Prioritization
- Prioritize chunks by:
  1. Semantic relevance (cosine similarity)
  2. Temporal recency (time-decay)
  3. Modality diversity (balance transcripts/frames/chat)
- Fill context budget with highest-priority chunks

---

## 7. Success Metrics

### ✅ Working Well
1. **Video Descriptions**: High quality, no refusals, maintaining visual understanding
2. **Memory Propagation**: Summaries successfully include previous context
3. **Summary Quality**: Comprehensive, well-structured, temporally accurate
4. **Background Job**: Running every 2 minutes, processing segments correctly

### ⚠️ Needs Attention
1. **RAG Context Exhaustion**: Most recent summary dominates context, blocking other relevant chunks
2. **Summary Length**: 15-50% longer than target, causing context budget issues
3. **Token Costs**: High input tokens (15k-23k) due to large context windows

### ❌ Critical Issues
1. **RAG Context Limit Too Small**: 2000 chars insufficient for summary + other context
2. **No Semantic Retrieval in RAG**: Only most recent summary returned, no other relevant chunks

---

## 8. Action Items

### Priority 1 (Immediate)
1. **Increase `DEFAULT_CONTEXT_CHAR_LIMIT` to 8000** in `py/reason/rag.py`
2. **Update summary prompt** to target 200-350 words instead of 300-500
3. **Add summary truncation** in `_retrieve_chunks()` if summary exceeds 30% of budget

### Priority 2 (Short-term)
1. **Implement adaptive context budget** allocation
2. **Add summary compression** for RAG context
3. **Optimize summarization context** (reduce frame/chat verbosity)

### Priority 3 (Long-term)
1. **Two-tier summary system** (short + detailed)
2. **Chunk prioritization** algorithm
3. **Token usage monitoring** and alerts

---

## Appendix: Sample Context Breakdown

### Segment 21:50-21:52 (Busy Segment)
- **Transcripts**: 9 chunks (~450 tokens)
- **Video Frames**: 12 frames × ~400 tokens = ~4,800 tokens
- **Chat Messages**: 377 messages × ~10 tokens = ~3,770 tokens
- **Previous Summary**: ~600 tokens
- **Prompts**: ~500 tokens
- **Total**: ~10,000 tokens (estimated)
- **Actual**: 17,501 tokens (gap suggests enriched context adds significant overhead)

### RAG Query Context (Current)
- **Most Recent Summary**: ~2,500 chars (exceeds 2000 char limit)
- **Other Chunks**: 0 (no room)
- **Total**: 2,500 chars (over limit, likely truncated)

### RAG Query Context (Recommended)
- **Most Recent Summary**: ~1,500 chars (30% of 5000 char budget)
- **Semantic Chunks**: ~3,500 chars (70% of budget, ~5-7 chunks)
- **Total**: ~5,000 chars (within 8000 char limit)

